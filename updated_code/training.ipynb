{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import csv\n","import pandas as pd\n","from tensorflow import keras\n","from sklearn.model_selection import train_test_split\n","from data import BodyPart \n","import tensorflow as tf\n","import tensorflowjs as tfjs\n","from tensorflow.keras.optimizers import Adam\n","\n","tfjs_model_dir = 'model'"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# loading final csv file\n","def load_csv(csv_path):\n","    df = pd.read_csv(csv_path)\n","    df.drop(['filename'],axis=1, inplace=True)\n","    classes = df.pop('class_name').unique()\n","    y = df.pop('class_no')\n","    \n","    X = df.astype('float64')\n","    y = keras.utils.to_categorical(y)\n","    \n","    return X, y, classes"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["def get_center_point(landmarks, left_bodypart, right_bodypart):\n","    \"\"\"Calculates the center point of the two given landmarks.\"\"\"\n","    left = tf.gather(landmarks, left_bodypart.value, axis=1)\n","    right = tf.gather(landmarks, right_bodypart.value, axis=1)\n","    center = left * 0.5 + right * 0.5\n","    return center"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["def get_pose_size(landmarks, torso_size_multiplier=2.5):\n","    \"\"\"Calculates pose size.\n","\n","    It is the maximum of two values:\n","    * Torso size multiplied by `torso_size_multiplier`\n","    * Maximum distance from pose center to any pose landmark\n","    \"\"\"\n","    # Hips center\n","    hips_center = get_center_point(landmarks, BodyPart.LEFT_HIP, \n","                                 BodyPart.RIGHT_HIP)\n","\n","    # Shoulders center\n","    shoulders_center = get_center_point(landmarks, BodyPart.LEFT_SHOULDER,\n","                                      BodyPart.RIGHT_SHOULDER)\n","\n","    # Torso size as the minimum body size\n","    torso_size = tf.linalg.norm(shoulders_center - hips_center)\n","    # Pose center\n","    pose_center_new = get_center_point(landmarks, BodyPart.LEFT_HIP, \n","                                     BodyPart.RIGHT_HIP)\n","    pose_center_new = tf.expand_dims(pose_center_new, axis=1)\n","    # Broadcast the pose center to the same size as the landmark vector to\n","    # perform substraction\n","    pose_center_new = tf.broadcast_to(pose_center_new,\n","                                    [tf.size(landmarks) // (17*2), 17, 2])\n","\n","    # Dist to pose center\n","    d = tf.gather(landmarks - pose_center_new, 0, axis=0,\n","                name=\"dist_to_pose_center\")\n","    # Max dist to pose center\n","    max_dist = tf.reduce_max(tf.linalg.norm(d, axis=0))\n","\n","    # Normalize scale\n","    pose_size = tf.maximum(torso_size * torso_size_multiplier, max_dist)\n","    return pose_size"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["def normalize_pose_landmarks(landmarks):\n","    \"\"\"Normalizes the landmarks translation by moving the pose center to (0,0) and\n","    scaling it to a constant pose size.\n","  \"\"\"\n","  # Move landmarks so that the pose center becomes (0,0)\n","    pose_center = get_center_point(landmarks, BodyPart.LEFT_HIP, \n","                                 BodyPart.RIGHT_HIP)\n","\n","    pose_center = tf.expand_dims(pose_center, axis=1)\n","    # Broadcast the pose center to the same size as the landmark vector to perform\n","    # substraction\n","    pose_center = tf.broadcast_to(pose_center, \n","                                [tf.size(landmarks) // (17*2), 17, 2])\n","    landmarks = landmarks - pose_center\n","\n","    # Scale the landmarks to a constant pose size\n","    pose_size = get_pose_size(landmarks)\n","    landmarks /= pose_size\n","    return landmarks"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["def landmarks_to_embedding(landmarks_and_scores):\n","    \"\"\"Converts the input landmarks into a pose embedding.\"\"\"\n","    # Reshape the flat input into a matrix with shape=(17, 3)\n","    reshaped_inputs = keras.layers.Reshape((17, 3))(landmarks_and_scores)\n","\n","    # Normalize landmarks 2D\n","    landmarks = normalize_pose_landmarks(reshaped_inputs[:, :, :2])\n","    # Flatten the normalized landmark coordinates into a vector\n","    embedding = keras.layers.Flatten()(landmarks)\n","    return embedding"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["def preprocess_data(X_train):\n","    processed_X_train = []\n","    for i in range(X_train.shape[0]):\n","        embedding = landmarks_to_embedding(tf.reshape(tf.convert_to_tensor(X_train.iloc[i]), (1, 51)))\n","        processed_X_train.append(tf.reshape(embedding, (34)))\n","    return tf.convert_to_tensor(processed_X_train)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["X, y, class_names = load_csv('train_data.csv')\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.15)\n","X_test, y_test, _ = load_csv('test_data.csv')"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2022-05-16 14:49:57.445112: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]},{"name":"stdout","output_type":"stream","text":["Model: \"model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 34)]              0         \n","                                                                 \n"," dense (Dense)               (None, 128)               4480      \n","                                                                 \n"," dropout (Dropout)           (None, 128)               0         \n","                                                                 \n"," dense_1 (Dense)             (None, 64)                8256      \n","                                                                 \n"," dropout_1 (Dropout)         (None, 64)                0         \n","                                                                 \n"," dense_2 (Dense)             (None, 13)                845       \n","                                                                 \n","=================================================================\n","Total params: 13,581\n","Trainable params: 13,581\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["processed_X_train = preprocess_data(X_train)\n","processed_X_val =  preprocess_data(X_val)\n","processed_X_test = preprocess_data(X_test)\n","\n","inputs = tf.keras.Input(shape=(34))\n","layer = keras.layers.Dense(128, activation=tf.nn.relu6)(inputs)\n","layer = keras.layers.Dropout(0.5)(layer)\n","layer = keras.layers.Dense(64, activation=tf.nn.relu6)(layer)\n","layer = keras.layers.Dropout(0.5)(layer)\n","outputs = keras.layers.Dense(len(class_names), activation=\"softmax\")(layer)\n","\n","model = keras.Model(inputs, outputs)\n","model.summary()\n","\n","\n","model.compile(\n","    optimizer = Adam(learning_rate=0.005),\n","    loss='categorical_crossentropy',\n","    metrics=['accuracy']\n",")"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["checkpoint_path = \"weights.best.hdf5\"\n","checkpoint = keras.callbacks.ModelCheckpoint(checkpoint_path,\n","                             monitor='val_accuracy',\n","                             verbose=1,\n","                             save_best_only=True,\n","                             mode='max')\n","earlystopping = keras.callbacks.EarlyStopping(monitor='val_accuracy', \n","                                              patience=20)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["--------------TRAINING----------------\n","Epoch 1/200\n","12/12 [==============================] - 0s 6ms/step - loss: 0.1179 - accuracy: 0.9605 - val_loss: 0.3718 - val_accuracy: 0.9365\n","Epoch 2/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.2087 - accuracy: 0.9379 - val_loss: 0.4480 - val_accuracy: 0.9048\n","Epoch 3/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.2067 - accuracy: 0.9435 - val_loss: 0.4021 - val_accuracy: 0.9365\n","Epoch 4/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1924 - accuracy: 0.9492 - val_loss: 0.3890 - val_accuracy: 0.9365\n","Epoch 5/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.2025 - accuracy: 0.9435 - val_loss: 0.3756 - val_accuracy: 0.9365\n","Epoch 6/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.2034 - accuracy: 0.9435 - val_loss: 0.4614 - val_accuracy: 0.9365\n","Epoch 7/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1877 - accuracy: 0.9407 - val_loss: 0.4340 - val_accuracy: 0.9365\n","Epoch 8/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1216 - accuracy: 0.9520 - val_loss: 0.4090 - val_accuracy: 0.9365\n","Epoch 9/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1725 - accuracy: 0.9435 - val_loss: 0.3826 - val_accuracy: 0.9365\n","Epoch 10/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1185 - accuracy: 0.9576 - val_loss: 0.3488 - val_accuracy: 0.9365\n","Epoch 11/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1495 - accuracy: 0.9520 - val_loss: 0.3344 - val_accuracy: 0.9365\n","Epoch 12/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1118 - accuracy: 0.9718 - val_loss: 0.3524 - val_accuracy: 0.9365\n","Epoch 13/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1005 - accuracy: 0.9633 - val_loss: 0.3781 - val_accuracy: 0.9365\n","Epoch 14/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1217 - accuracy: 0.9548 - val_loss: 0.3652 - val_accuracy: 0.9365\n","Epoch 15/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1379 - accuracy: 0.9520 - val_loss: 0.3888 - val_accuracy: 0.9365\n","Epoch 16/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1429 - accuracy: 0.9548 - val_loss: 0.3877 - val_accuracy: 0.9365\n","Epoch 17/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1079 - accuracy: 0.9746 - val_loss: 0.3559 - val_accuracy: 0.9365\n","Epoch 18/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0992 - accuracy: 0.9633 - val_loss: 0.3301 - val_accuracy: 0.9365\n","Epoch 19/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0956 - accuracy: 0.9633 - val_loss: 0.3575 - val_accuracy: 0.9365\n","Epoch 20/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1273 - accuracy: 0.9605 - val_loss: 0.3371 - val_accuracy: 0.9365\n","Epoch 21/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0762 - accuracy: 0.9774 - val_loss: 0.3355 - val_accuracy: 0.9365\n","Epoch 22/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0908 - accuracy: 0.9718 - val_loss: 0.3821 - val_accuracy: 0.9365\n","Epoch 23/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0798 - accuracy: 0.9746 - val_loss: 0.4009 - val_accuracy: 0.9365\n","Epoch 24/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0812 - accuracy: 0.9718 - val_loss: 0.3761 - val_accuracy: 0.9365\n","Epoch 25/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0958 - accuracy: 0.9576 - val_loss: 0.3588 - val_accuracy: 0.9365\n","Epoch 26/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1040 - accuracy: 0.9605 - val_loss: 0.3481 - val_accuracy: 0.9365\n","Epoch 27/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1109 - accuracy: 0.9633 - val_loss: 0.3422 - val_accuracy: 0.9365\n","Epoch 28/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1284 - accuracy: 0.9689 - val_loss: 0.3655 - val_accuracy: 0.9206\n","Epoch 29/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1261 - accuracy: 0.9576 - val_loss: 0.3847 - val_accuracy: 0.9365\n","Epoch 30/200\n","12/12 [==============================] - 0s 4ms/step - loss: 0.1068 - accuracy: 0.9633 - val_loss: 0.3679 - val_accuracy: 0.9365\n","Epoch 31/200\n","12/12 [==============================] - 0s 4ms/step - loss: 0.0794 - accuracy: 0.9689 - val_loss: 0.4116 - val_accuracy: 0.9365\n","Epoch 32/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0977 - accuracy: 0.9633 - val_loss: 0.4277 - val_accuracy: 0.9365\n","Epoch 33/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1218 - accuracy: 0.9661 - val_loss: 0.4180 - val_accuracy: 0.9365\n","Epoch 34/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1020 - accuracy: 0.9661 - val_loss: 0.3846 - val_accuracy: 0.9365\n","Epoch 35/200\n","12/12 [==============================] - 0s 4ms/step - loss: 0.1108 - accuracy: 0.9661 - val_loss: 0.4035 - val_accuracy: 0.9365\n","Epoch 36/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0925 - accuracy: 0.9718 - val_loss: 0.4271 - val_accuracy: 0.9365\n","Epoch 37/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0706 - accuracy: 0.9859 - val_loss: 0.4484 - val_accuracy: 0.9365\n","Epoch 38/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0844 - accuracy: 0.9718 - val_loss: 0.4423 - val_accuracy: 0.9365\n","Epoch 39/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0932 - accuracy: 0.9661 - val_loss: 0.4692 - val_accuracy: 0.9365\n","Epoch 40/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1021 - accuracy: 0.9661 - val_loss: 0.4589 - val_accuracy: 0.9365\n","Epoch 41/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0944 - accuracy: 0.9746 - val_loss: 0.4600 - val_accuracy: 0.9365\n","Epoch 42/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1047 - accuracy: 0.9746 - val_loss: 0.4550 - val_accuracy: 0.9365\n","Epoch 43/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0678 - accuracy: 0.9774 - val_loss: 0.4509 - val_accuracy: 0.9365\n","Epoch 44/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0778 - accuracy: 0.9689 - val_loss: 0.4599 - val_accuracy: 0.9365\n","Epoch 45/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0932 - accuracy: 0.9605 - val_loss: 0.4475 - val_accuracy: 0.9365\n","Epoch 46/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1053 - accuracy: 0.9774 - val_loss: 0.4127 - val_accuracy: 0.9365\n","Epoch 47/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0942 - accuracy: 0.9576 - val_loss: 0.3943 - val_accuracy: 0.9365\n","Epoch 48/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1098 - accuracy: 0.9633 - val_loss: 0.4329 - val_accuracy: 0.9365\n","Epoch 49/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0996 - accuracy: 0.9689 - val_loss: 0.4295 - val_accuracy: 0.9365\n","Epoch 50/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0872 - accuracy: 0.9633 - val_loss: 0.4214 - val_accuracy: 0.9365\n","Epoch 51/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0810 - accuracy: 0.9774 - val_loss: 0.4289 - val_accuracy: 0.9365\n","Epoch 52/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0826 - accuracy: 0.9661 - val_loss: 0.4103 - val_accuracy: 0.9365\n","Epoch 53/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0868 - accuracy: 0.9661 - val_loss: 0.4149 - val_accuracy: 0.9365\n","Epoch 54/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0798 - accuracy: 0.9746 - val_loss: 0.4224 - val_accuracy: 0.9365\n","Epoch 55/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0656 - accuracy: 0.9859 - val_loss: 0.4342 - val_accuracy: 0.9365\n","Epoch 56/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0836 - accuracy: 0.9802 - val_loss: 0.4413 - val_accuracy: 0.9365\n","Epoch 57/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0886 - accuracy: 0.9661 - val_loss: 0.4457 - val_accuracy: 0.9365\n","Epoch 58/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1164 - accuracy: 0.9633 - val_loss: 0.3737 - val_accuracy: 0.9365\n","Epoch 59/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.2051 - accuracy: 0.9266 - val_loss: 0.3608 - val_accuracy: 0.9365\n","Epoch 60/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1620 - accuracy: 0.9548 - val_loss: 0.3618 - val_accuracy: 0.9365\n","Epoch 61/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1685 - accuracy: 0.9492 - val_loss: 0.3504 - val_accuracy: 0.9365\n","Epoch 62/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1521 - accuracy: 0.9435 - val_loss: 0.3257 - val_accuracy: 0.9365\n","Epoch 63/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1249 - accuracy: 0.9548 - val_loss: 0.3541 - val_accuracy: 0.9365\n","Epoch 64/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1077 - accuracy: 0.9661 - val_loss: 0.3668 - val_accuracy: 0.9365\n","Epoch 65/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0963 - accuracy: 0.9802 - val_loss: 0.3835 - val_accuracy: 0.9365\n","Epoch 66/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1301 - accuracy: 0.9661 - val_loss: 0.3219 - val_accuracy: 0.9365\n","Epoch 67/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1288 - accuracy: 0.9661 - val_loss: 0.3338 - val_accuracy: 0.9365\n","Epoch 68/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1165 - accuracy: 0.9605 - val_loss: 0.3842 - val_accuracy: 0.9365\n","Epoch 69/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1249 - accuracy: 0.9633 - val_loss: 0.4063 - val_accuracy: 0.9365\n","Epoch 70/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0881 - accuracy: 0.9746 - val_loss: 0.4170 - val_accuracy: 0.9365\n","Epoch 71/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0833 - accuracy: 0.9774 - val_loss: 0.4083 - val_accuracy: 0.9365\n","Epoch 72/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0899 - accuracy: 0.9689 - val_loss: 0.4105 - val_accuracy: 0.9365\n","Epoch 73/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1172 - accuracy: 0.9520 - val_loss: 0.3846 - val_accuracy: 0.9365\n","Epoch 74/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1008 - accuracy: 0.9746 - val_loss: 0.4107 - val_accuracy: 0.9365\n","Epoch 75/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0966 - accuracy: 0.9605 - val_loss: 0.4638 - val_accuracy: 0.9365\n","Epoch 76/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1480 - accuracy: 0.9548 - val_loss: 0.4601 - val_accuracy: 0.9365\n","Epoch 77/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0985 - accuracy: 0.9746 - val_loss: 0.4623 - val_accuracy: 0.9365\n","Epoch 78/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1110 - accuracy: 0.9463 - val_loss: 0.4285 - val_accuracy: 0.9365\n","Epoch 79/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1121 - accuracy: 0.9689 - val_loss: 0.4398 - val_accuracy: 0.9365\n","Epoch 80/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0948 - accuracy: 0.9689 - val_loss: 0.4444 - val_accuracy: 0.9365\n","Epoch 81/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0995 - accuracy: 0.9605 - val_loss: 0.4487 - val_accuracy: 0.9365\n","Epoch 82/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1293 - accuracy: 0.9520 - val_loss: 0.4297 - val_accuracy: 0.9365\n","Epoch 83/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1016 - accuracy: 0.9661 - val_loss: 0.4122 - val_accuracy: 0.9365\n","Epoch 84/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1012 - accuracy: 0.9605 - val_loss: 0.4589 - val_accuracy: 0.9365\n","Epoch 85/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1057 - accuracy: 0.9633 - val_loss: 0.4610 - val_accuracy: 0.9365\n","Epoch 86/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1080 - accuracy: 0.9633 - val_loss: 0.4607 - val_accuracy: 0.9365\n","Epoch 87/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0955 - accuracy: 0.9689 - val_loss: 0.4399 - val_accuracy: 0.9365\n","Epoch 88/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0793 - accuracy: 0.9802 - val_loss: 0.4365 - val_accuracy: 0.9365\n","Epoch 89/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1024 - accuracy: 0.9661 - val_loss: 0.5131 - val_accuracy: 0.9206\n","Epoch 90/200\n","12/12 [==============================] - 0s 4ms/step - loss: 0.1060 - accuracy: 0.9774 - val_loss: 0.5294 - val_accuracy: 0.9206\n","Epoch 91/200\n","12/12 [==============================] - 0s 4ms/step - loss: 0.1077 - accuracy: 0.9605 - val_loss: 0.5103 - val_accuracy: 0.9206\n","Epoch 92/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0959 - accuracy: 0.9746 - val_loss: 0.4972 - val_accuracy: 0.9206\n","Epoch 93/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1411 - accuracy: 0.9633 - val_loss: 0.4609 - val_accuracy: 0.9365\n","Epoch 94/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0587 - accuracy: 0.9831 - val_loss: 0.4631 - val_accuracy: 0.9365\n","Epoch 95/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1524 - accuracy: 0.9576 - val_loss: 0.5077 - val_accuracy: 0.9365\n","Epoch 96/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0941 - accuracy: 0.9774 - val_loss: 0.5102 - val_accuracy: 0.9365\n","Epoch 97/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0964 - accuracy: 0.9689 - val_loss: 0.4922 - val_accuracy: 0.9365\n","Epoch 98/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0808 - accuracy: 0.9774 - val_loss: 0.4595 - val_accuracy: 0.9365\n","Epoch 99/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1090 - accuracy: 0.9689 - val_loss: 0.4406 - val_accuracy: 0.9206\n","Epoch 100/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0550 - accuracy: 0.9859 - val_loss: 0.4482 - val_accuracy: 0.9206\n","Epoch 101/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1228 - accuracy: 0.9576 - val_loss: 0.4474 - val_accuracy: 0.9365\n","Epoch 102/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1208 - accuracy: 0.9548 - val_loss: 0.4338 - val_accuracy: 0.9365\n","Epoch 103/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1298 - accuracy: 0.9576 - val_loss: 0.4216 - val_accuracy: 0.9365\n","Epoch 104/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1104 - accuracy: 0.9689 - val_loss: 0.3990 - val_accuracy: 0.9365\n","Epoch 105/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0987 - accuracy: 0.9689 - val_loss: 0.4548 - val_accuracy: 0.9365\n","Epoch 106/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1312 - accuracy: 0.9576 - val_loss: 0.4687 - val_accuracy: 0.9365\n","Epoch 107/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1016 - accuracy: 0.9661 - val_loss: 0.5266 - val_accuracy: 0.9365\n","Epoch 108/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1138 - accuracy: 0.9633 - val_loss: 0.5117 - val_accuracy: 0.9365\n","Epoch 109/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1212 - accuracy: 0.9407 - val_loss: 0.4803 - val_accuracy: 0.9365\n","Epoch 110/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1424 - accuracy: 0.9520 - val_loss: 0.4410 - val_accuracy: 0.9365\n","Epoch 111/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1182 - accuracy: 0.9718 - val_loss: 0.4246 - val_accuracy: 0.9365\n","Epoch 112/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1439 - accuracy: 0.9463 - val_loss: 0.3821 - val_accuracy: 0.9365\n","Epoch 113/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1537 - accuracy: 0.9435 - val_loss: 0.3961 - val_accuracy: 0.9365\n","Epoch 114/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0910 - accuracy: 0.9746 - val_loss: 0.3883 - val_accuracy: 0.9365\n","Epoch 115/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0747 - accuracy: 0.9661 - val_loss: 0.3699 - val_accuracy: 0.9365\n","Epoch 116/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1222 - accuracy: 0.9520 - val_loss: 0.3641 - val_accuracy: 0.9365\n","Epoch 117/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1094 - accuracy: 0.9548 - val_loss: 0.3698 - val_accuracy: 0.9365\n","Epoch 118/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0979 - accuracy: 0.9633 - val_loss: 0.3920 - val_accuracy: 0.9365\n","Epoch 119/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0727 - accuracy: 0.9746 - val_loss: 0.4043 - val_accuracy: 0.9365\n","Epoch 120/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0970 - accuracy: 0.9689 - val_loss: 0.4002 - val_accuracy: 0.9365\n","Epoch 121/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1087 - accuracy: 0.9605 - val_loss: 0.3990 - val_accuracy: 0.9365\n","Epoch 122/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0813 - accuracy: 0.9831 - val_loss: 0.3913 - val_accuracy: 0.9365\n","Epoch 123/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0709 - accuracy: 0.9689 - val_loss: 0.3875 - val_accuracy: 0.9365\n","Epoch 124/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1653 - accuracy: 0.9520 - val_loss: 0.4005 - val_accuracy: 0.9365\n","Epoch 125/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0715 - accuracy: 0.9774 - val_loss: 0.3822 - val_accuracy: 0.9365\n","Epoch 126/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0929 - accuracy: 0.9774 - val_loss: 0.3697 - val_accuracy: 0.9365\n","Epoch 127/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0757 - accuracy: 0.9802 - val_loss: 0.4090 - val_accuracy: 0.9365\n","Epoch 128/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0781 - accuracy: 0.9661 - val_loss: 0.4438 - val_accuracy: 0.9365\n","Epoch 129/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1086 - accuracy: 0.9661 - val_loss: 0.4321 - val_accuracy: 0.9365\n","Epoch 130/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1317 - accuracy: 0.9605 - val_loss: 0.3543 - val_accuracy: 0.9365\n","Epoch 131/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0890 - accuracy: 0.9661 - val_loss: 0.3671 - val_accuracy: 0.9365\n","Epoch 132/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1839 - accuracy: 0.9548 - val_loss: 0.4028 - val_accuracy: 0.9365\n","Epoch 133/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1000 - accuracy: 0.9718 - val_loss: 0.3081 - val_accuracy: 0.9365\n","Epoch 134/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.2040 - accuracy: 0.9463 - val_loss: 0.3011 - val_accuracy: 0.9365\n","Epoch 135/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1095 - accuracy: 0.9548 - val_loss: 0.3110 - val_accuracy: 0.9365\n","Epoch 136/200\n","12/12 [==============================] - 0s 6ms/step - loss: 0.1891 - accuracy: 0.9350 - val_loss: 0.2955 - val_accuracy: 0.9365\n","Epoch 137/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1470 - accuracy: 0.9435 - val_loss: 0.3201 - val_accuracy: 0.9365\n","Epoch 138/200\n","12/12 [==============================] - 0s 4ms/step - loss: 0.1105 - accuracy: 0.9605 - val_loss: 0.3265 - val_accuracy: 0.9365\n","Epoch 139/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0695 - accuracy: 0.9802 - val_loss: 0.3388 - val_accuracy: 0.9365\n","Epoch 140/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1373 - accuracy: 0.9576 - val_loss: 0.3241 - val_accuracy: 0.9365\n","Epoch 141/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1246 - accuracy: 0.9633 - val_loss: 0.4333 - val_accuracy: 0.9206\n","Epoch 142/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0949 - accuracy: 0.9605 - val_loss: 0.4408 - val_accuracy: 0.9365\n","Epoch 143/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1464 - accuracy: 0.9492 - val_loss: 0.4862 - val_accuracy: 0.9206\n","Epoch 144/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1356 - accuracy: 0.9633 - val_loss: 0.4815 - val_accuracy: 0.9206\n","Epoch 145/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1343 - accuracy: 0.9605 - val_loss: 0.4102 - val_accuracy: 0.9206\n","Epoch 146/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0950 - accuracy: 0.9689 - val_loss: 0.2869 - val_accuracy: 0.9365\n","Epoch 147/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1129 - accuracy: 0.9689 - val_loss: 0.3115 - val_accuracy: 0.9365\n","Epoch 148/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1673 - accuracy: 0.9407 - val_loss: 0.3510 - val_accuracy: 0.9365\n","Epoch 149/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0799 - accuracy: 0.9802 - val_loss: 0.3646 - val_accuracy: 0.9365\n","Epoch 150/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0850 - accuracy: 0.9831 - val_loss: 0.3463 - val_accuracy: 0.9365\n","Epoch 151/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1210 - accuracy: 0.9605 - val_loss: 0.3231 - val_accuracy: 0.9365\n","Epoch 152/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1046 - accuracy: 0.9548 - val_loss: 0.3282 - val_accuracy: 0.9206\n","Epoch 153/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1200 - accuracy: 0.9633 - val_loss: 0.3571 - val_accuracy: 0.9206\n","Epoch 154/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0881 - accuracy: 0.9774 - val_loss: 0.3167 - val_accuracy: 0.9365\n","Epoch 155/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1042 - accuracy: 0.9633 - val_loss: 0.2984 - val_accuracy: 0.9524\n","Epoch 156/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0812 - accuracy: 0.9774 - val_loss: 0.2969 - val_accuracy: 0.9524\n","Epoch 157/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1012 - accuracy: 0.9661 - val_loss: 0.3022 - val_accuracy: 0.9365\n","Epoch 158/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1045 - accuracy: 0.9774 - val_loss: 0.3200 - val_accuracy: 0.9365\n","Epoch 159/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0922 - accuracy: 0.9746 - val_loss: 0.3070 - val_accuracy: 0.9365\n","Epoch 160/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1244 - accuracy: 0.9633 - val_loss: 0.3143 - val_accuracy: 0.9365\n","Epoch 161/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0933 - accuracy: 0.9689 - val_loss: 0.3112 - val_accuracy: 0.9365\n","Epoch 162/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1032 - accuracy: 0.9576 - val_loss: 0.3623 - val_accuracy: 0.9365\n","Epoch 163/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1022 - accuracy: 0.9605 - val_loss: 0.3612 - val_accuracy: 0.9365\n","Epoch 164/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1213 - accuracy: 0.9605 - val_loss: 0.3413 - val_accuracy: 0.9365\n","Epoch 165/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1297 - accuracy: 0.9520 - val_loss: 0.3205 - val_accuracy: 0.9365\n","Epoch 166/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1460 - accuracy: 0.9435 - val_loss: 0.3140 - val_accuracy: 0.9206\n","Epoch 167/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0965 - accuracy: 0.9548 - val_loss: 0.3316 - val_accuracy: 0.9206\n","Epoch 168/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0832 - accuracy: 0.9718 - val_loss: 0.3695 - val_accuracy: 0.9206\n","Epoch 169/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0643 - accuracy: 0.9774 - val_loss: 0.3867 - val_accuracy: 0.9206\n","Epoch 170/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1184 - accuracy: 0.9633 - val_loss: 0.4431 - val_accuracy: 0.9206\n","Epoch 171/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1877 - accuracy: 0.9576 - val_loss: 0.3329 - val_accuracy: 0.9365\n","Epoch 172/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1815 - accuracy: 0.9435 - val_loss: 0.3230 - val_accuracy: 0.9365\n","Epoch 173/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0865 - accuracy: 0.9689 - val_loss: 0.3235 - val_accuracy: 0.9365\n","Epoch 174/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1337 - accuracy: 0.9576 - val_loss: 0.3184 - val_accuracy: 0.9365\n","Epoch 175/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0847 - accuracy: 0.9746 - val_loss: 0.3435 - val_accuracy: 0.9365\n","Epoch 176/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1243 - accuracy: 0.9605 - val_loss: 0.3525 - val_accuracy: 0.9365\n","Epoch 177/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0585 - accuracy: 0.9802 - val_loss: 0.3702 - val_accuracy: 0.9365\n","Epoch 178/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1153 - accuracy: 0.9661 - val_loss: 0.4120 - val_accuracy: 0.9365\n","Epoch 179/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0751 - accuracy: 0.9831 - val_loss: 0.4139 - val_accuracy: 0.9365\n","Epoch 180/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0878 - accuracy: 0.9689 - val_loss: 0.4037 - val_accuracy: 0.9365\n","Epoch 181/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0892 - accuracy: 0.9605 - val_loss: 0.3909 - val_accuracy: 0.9365\n","Epoch 182/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0645 - accuracy: 0.9802 - val_loss: 0.3973 - val_accuracy: 0.9365\n","Epoch 183/200\n","12/12 [==============================] - 0s 4ms/step - loss: 0.0639 - accuracy: 0.9859 - val_loss: 0.4024 - val_accuracy: 0.9365\n","Epoch 184/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0773 - accuracy: 0.9831 - val_loss: 0.4211 - val_accuracy: 0.9365\n","Epoch 185/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0800 - accuracy: 0.9831 - val_loss: 0.4485 - val_accuracy: 0.9206\n","Epoch 186/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1159 - accuracy: 0.9576 - val_loss: 0.4034 - val_accuracy: 0.9365\n","Epoch 187/200\n","12/12 [==============================] - 0s 4ms/step - loss: 0.0780 - accuracy: 0.9746 - val_loss: 0.3519 - val_accuracy: 0.9365\n","Epoch 188/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0864 - accuracy: 0.9633 - val_loss: 0.3690 - val_accuracy: 0.9365\n","Epoch 189/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0795 - accuracy: 0.9718 - val_loss: 0.3737 - val_accuracy: 0.9206\n","Epoch 190/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0991 - accuracy: 0.9718 - val_loss: 0.3749 - val_accuracy: 0.9206\n","Epoch 191/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1245 - accuracy: 0.9605 - val_loss: 0.3661 - val_accuracy: 0.9365\n","Epoch 192/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0777 - accuracy: 0.9661 - val_loss: 0.3726 - val_accuracy: 0.9365\n","Epoch 193/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0880 - accuracy: 0.9576 - val_loss: 0.3496 - val_accuracy: 0.9365\n","Epoch 194/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0862 - accuracy: 0.9689 - val_loss: 0.3930 - val_accuracy: 0.9365\n","Epoch 195/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0900 - accuracy: 0.9689 - val_loss: 0.4121 - val_accuracy: 0.9365\n","Epoch 196/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0819 - accuracy: 0.9689 - val_loss: 0.4318 - val_accuracy: 0.9206\n","Epoch 197/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0578 - accuracy: 0.9746 - val_loss: 0.3989 - val_accuracy: 0.9206\n","Epoch 198/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0723 - accuracy: 0.9746 - val_loss: 0.3329 - val_accuracy: 0.9365\n","Epoch 199/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.0986 - accuracy: 0.9689 - val_loss: 0.2736 - val_accuracy: 0.9365\n","Epoch 200/200\n","12/12 [==============================] - 0s 3ms/step - loss: 0.1026 - accuracy: 0.9746 - val_loss: 0.2591 - val_accuracy: 0.9365\n"]}],"source":["print('--------------TRAINING----------------')\n","history = model.fit(processed_X_train, y_train,\n","                    epochs=200,\n","                    batch_size=32,\n","                    validation_data=(processed_X_val, y_val))\n","                    # callbacks=[checkpoint, earlystopping])"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["-----------------EVAUATION----------------\n","4/4 [==============================] - 0s 1ms/step - loss: 0.2642 - accuracy: 0.9391\n","LOSS:  0.2642013132572174\n","ACCURACY:  0.939130425453186\n"]}],"source":["print('-----------------EVAUATION----------------')\n","loss, accuracy = model.evaluate(processed_X_test, y_test)\n","print('LOSS: ', loss)\n","print(\"ACCURACY: \", accuracy)"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tfjs model saved at  model\n"]}],"source":["tfjs.converters.save_keras_model(model, tfjs_model_dir)\n","print('tfjs model saved at ',tfjs_model_dir)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/plain":["array([[3.27806867e-14, 8.17371388e-19, 1.15327104e-20, 1.14494332e-26,\n","        2.90138833e-15, 5.34582274e-11, 6.23879878e-30, 4.64316764e-22,\n","        9.67718700e-12, 1.00000000e+00, 3.33662499e-15, 1.36327409e-18,\n","        2.78417400e-10],\n","       [1.98561447e-17, 4.71510721e-21, 1.02489696e-12, 1.93648408e-16,\n","        3.50802831e-18, 8.15638200e-17, 1.52260432e-16, 4.25918659e-16,\n","        4.93279124e-14, 4.13382653e-12, 2.89451991e-12, 9.86779809e-01,\n","        1.32201836e-02],\n","       [4.92870896e-16, 9.99992490e-01, 7.84107293e-23, 8.04036164e-20,\n","        9.55016178e-29, 7.53417362e-06, 1.07911270e-27, 2.76015647e-34,\n","        0.00000000e+00, 0.00000000e+00, 1.03413714e-34, 4.08666029e-34,\n","        6.80754206e-35],\n","       [1.13576373e-35, 2.77265872e-21, 6.28759045e-10, 1.86452652e-18,\n","        2.45266531e-29, 3.11440282e-27, 4.40677361e-15, 4.03289176e-26,\n","        1.63954083e-13, 2.73967555e-22, 1.00000000e+00, 3.00979814e-12,\n","        6.81975960e-12],\n","       [2.77094229e-16, 2.32178094e-23, 1.66128640e-13, 5.13332876e-10,\n","        2.53163155e-14, 9.09077249e-23, 4.06363518e-35, 4.03085651e-36,\n","        7.89311573e-29, 1.44894565e-19, 2.07154007e-19, 8.39581768e-14,\n","        1.00000000e+00],\n","       [7.51302576e-10, 1.05827534e-15, 4.78448670e-10, 1.45085565e-07,\n","        1.95242240e-08, 2.96688706e-14, 3.01917610e-23, 2.08320053e-23,\n","        9.30686860e-19, 3.02147250e-13, 1.17858053e-14, 3.31397954e-09,\n","        9.99999881e-01],\n","       [4.44907563e-17, 7.95805264e-20, 3.17109290e-11, 1.82502227e-14,\n","        7.00389243e-17, 8.63612929e-16, 1.73653291e-14, 2.01637379e-14,\n","        1.40086415e-13, 5.56779622e-12, 2.10976202e-11, 9.79176700e-01,\n","        2.08232459e-02],\n","       [7.29876554e-13, 6.49585529e-13, 3.64706680e-15, 1.05766885e-04,\n","        1.04193136e-01, 1.53277857e-09, 5.55143043e-10, 8.95701110e-01,\n","        1.31628161e-13, 3.57852803e-10, 2.43626186e-09, 5.47752598e-12,\n","        2.31608335e-14],\n","       [4.76590947e-24, 1.00000000e+00, 6.79963591e-32, 8.29911353e-25,\n","        5.41230568e-37, 1.34776494e-13, 5.57047573e-36, 0.00000000e+00,\n","        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00],\n","       [1.19882023e-13, 3.37005319e-16, 1.22417238e-21, 2.25292727e-08,\n","        9.99986172e-01, 1.68347211e-11, 2.43075527e-19, 1.37553898e-05,\n","        5.40652858e-17, 1.60632434e-12, 2.57913464e-15, 9.70794677e-19,\n","        5.50790453e-18],\n","       [5.92723082e-13, 4.95784478e-15, 5.20644899e-12, 9.99999881e-01,\n","        1.37887156e-07, 3.08413878e-18, 2.33729625e-23, 2.21711667e-22,\n","        2.80197631e-26, 5.89814104e-26, 1.12354487e-16, 4.46875033e-14,\n","        2.32240849e-09],\n","       [2.70087230e-06, 2.97750230e-05, 6.41437061e-03, 1.57066458e-03,\n","        4.07335872e-04, 2.73418118e-05, 6.20982423e-03, 1.69669057e-03,\n","        2.06136089e-02, 2.80058768e-04, 2.75259674e-01, 5.70966423e-01,\n","        1.16521612e-01],\n","       [6.27097021e-35, 3.09713870e-21, 2.96462924e-11, 3.20067554e-20,\n","        7.07423258e-30, 2.54525875e-27, 2.10608340e-17, 1.48708495e-27,\n","        1.65824819e-12, 3.01847834e-20, 1.00000000e+00, 2.31630448e-12,\n","        1.63807336e-11],\n","       [5.59427535e-24, 1.00000000e+00, 1.01375799e-30, 6.92903865e-25,\n","        1.12556266e-36, 2.18858175e-13, 3.96393283e-35, 0.00000000e+00,\n","        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00],\n","       [5.93148414e-13, 9.88251074e-17, 1.04179180e-17, 8.81175112e-23,\n","        1.31267759e-13, 1.12945353e-09, 7.30995431e-26, 5.62220807e-19,\n","        1.48860188e-10, 1.00000000e+00, 7.96077885e-13, 3.61211536e-16,\n","        4.56358995e-09],\n","       [9.32818201e-22, 2.15400114e-21, 3.87540966e-17, 1.00000000e+00,\n","        1.87034524e-12, 5.45623609e-28, 1.02424445e-32, 7.40823264e-34,\n","        0.00000000e+00, 0.00000000e+00, 1.01010937e-24, 6.10677548e-22,\n","        5.76983279e-16],\n","       [0.00000000e+00, 1.81545592e-37, 1.00000000e+00, 5.12524390e-15,\n","        0.00000000e+00, 8.76616577e-28, 1.83642295e-28, 0.00000000e+00,\n","        0.00000000e+00, 0.00000000e+00, 1.40103083e-29, 3.58938750e-36,\n","        3.44496716e-25],\n","       [1.98512918e-23, 1.00000000e+00, 1.17516756e-31, 5.14414224e-24,\n","        3.74412278e-36, 6.73744643e-14, 1.86030357e-36, 0.00000000e+00,\n","        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00],\n","       [4.72945715e-22, 1.00000000e+00, 2.31244859e-29, 2.27701261e-23,\n","        4.97370658e-35, 1.47551231e-12, 1.14556769e-34, 0.00000000e+00,\n","        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00],\n","       [1.36844979e-23, 1.00000000e+00, 2.37878068e-31, 1.89903373e-24,\n","        1.05565943e-36, 3.32602835e-14, 1.90455017e-36, 0.00000000e+00,\n","        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00],\n","       [5.79451027e-12, 5.75945611e-17, 3.07648239e-04, 2.85768631e-10,\n","        2.24782797e-11, 9.94229224e-04, 6.95697215e-22, 2.81358894e-19,\n","        3.45700000e-19, 9.57472707e-07, 2.69185779e-15, 3.04271504e-11,\n","        9.98697221e-01],\n","       [1.70196616e-03, 4.28782254e-09, 1.03155521e-13, 4.97978947e-09,\n","        9.98295963e-01, 1.15824116e-06, 4.20267407e-17, 1.56265398e-12,\n","        6.43935530e-11, 1.09201224e-07, 8.23595037e-15, 3.23730182e-10,\n","        8.44007900e-07],\n","       [2.48993182e-13, 2.69686804e-17, 2.67742131e-18, 7.26708842e-24,\n","        2.61775973e-14, 4.00897343e-10, 5.14124996e-27, 2.96372254e-20,\n","        8.74830208e-11, 1.00000000e+00, 2.91299699e-13, 1.18465565e-16,\n","        3.86131838e-09],\n","       [1.02362225e-11, 7.27806906e-17, 1.07332546e-12, 8.92256705e-21,\n","        1.12431740e-14, 9.99999523e-01, 2.29474168e-28, 2.75367234e-22,\n","        7.35101587e-22, 4.51407345e-07, 1.37036766e-21, 1.16828185e-19,\n","        3.38372175e-08],\n","       [3.52977003e-33, 4.81914692e-31, 4.85072928e-21, 1.00000000e+00,\n","        4.39438491e-15, 7.81874557e-34, 0.00000000e+00, 2.31847073e-38,\n","        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 6.30203425e-25,\n","        4.82341768e-22],\n","       [9.99998689e-01, 3.69343560e-08, 6.25304357e-21, 1.76450839e-18,\n","        1.19759447e-09, 1.30779370e-06, 1.24927086e-29, 2.06512148e-28,\n","        1.06859764e-16, 7.03575874e-17, 1.74742867e-24, 1.27824944e-19,\n","        1.18151877e-10],\n","       [3.67299042e-04, 3.44889855e-07, 2.80193948e-08, 9.26555913e-06,\n","        9.03096020e-01, 3.58780799e-03, 7.99907784e-09, 4.33971873e-03,\n","        5.82540906e-06, 8.85050818e-02, 3.55266343e-06, 2.47804849e-07,\n","        8.47993433e-05],\n","       [7.00910857e-11, 3.35066154e-19, 1.72123704e-11, 6.41705427e-15,\n","        9.22325801e-13, 2.94518381e-12, 5.07179137e-25, 4.70315388e-22,\n","        1.19313324e-14, 1.23295851e-09, 1.36159293e-14, 1.24545538e-08,\n","        1.00000000e+00],\n","       [1.55177257e-16, 1.52049044e-20, 4.46021502e-13, 7.32345811e-17,\n","        5.92126488e-18, 1.15628931e-16, 4.26169275e-17, 2.42881510e-16,\n","        1.70144592e-13, 1.92691228e-11, 4.47512079e-12, 9.88042951e-01,\n","        1.19570298e-02],\n","       [2.01944269e-19, 1.00000000e+00, 9.04268297e-26, 9.58793914e-22,\n","        2.00193388e-32, 6.13500750e-10, 3.29850556e-31, 0.00000000e+00,\n","        0.00000000e+00, 0.00000000e+00, 3.39858239e-37, 1.59519423e-37,\n","        0.00000000e+00],\n","       [1.98937983e-06, 5.45947348e-13, 2.11698547e-17, 6.68851330e-09,\n","        9.99997973e-01, 5.15408514e-11, 2.97056290e-21, 5.52091501e-15,\n","        1.34423335e-15, 1.09829350e-11, 9.55449442e-18, 3.46598119e-12,\n","        7.00103087e-09],\n","       [1.15809049e-26, 1.40256943e-16, 1.18566135e-09, 4.95476105e-16,\n","        1.20864409e-22, 6.96990139e-22, 6.74341157e-14, 5.71570817e-21,\n","        1.65854164e-09, 6.37656832e-16, 1.00000000e+00, 3.36390826e-09,\n","        4.69705297e-09],\n","       [5.18865351e-17, 1.93142166e-20, 3.60118662e-12, 1.10880340e-15,\n","        1.39717870e-17, 3.62179615e-16, 9.74068831e-16, 2.61887341e-15,\n","        5.27553058e-14, 5.50490209e-12, 3.91025884e-12, 9.84382331e-01,\n","        1.56177077e-02],\n","       [6.84679466e-11, 6.20408759e-12, 1.79507879e-07, 7.70584818e-10,\n","        8.06355746e-11, 5.12294152e-10, 2.32363173e-09, 1.82209403e-09,\n","        2.11931962e-07, 7.30307022e-07, 2.17485331e-06, 9.54607189e-01,\n","        4.53894399e-02],\n","       [1.09494781e-10, 5.20171064e-14, 6.93807086e-18, 5.66121116e-06,\n","        9.99990702e-01, 2.18476945e-10, 2.45639340e-17, 3.64489779e-06,\n","        4.45092859e-15, 5.61438569e-12, 2.95177402e-13, 6.29494346e-15,\n","        1.12176334e-13],\n","       [4.87015823e-14, 1.58274342e-15, 6.47604842e-15, 4.96195923e-19,\n","        2.18843959e-13, 1.44875320e-10, 1.75526247e-22, 1.47857360e-17,\n","        7.55793028e-09, 9.99999881e-01, 7.45739381e-09, 1.30444849e-13,\n","        7.94605342e-08],\n","       [4.04529787e-09, 3.17462236e-01, 4.96852504e-10, 1.85634008e-10,\n","        1.53296554e-18, 6.82537794e-01, 9.64944504e-23, 1.30999405e-27,\n","        1.50529161e-30, 2.04274023e-30, 2.18465980e-25, 4.37575178e-25,\n","        6.32708098e-22],\n","       [1.16727948e-15, 1.97254555e-18, 3.71261563e-11, 1.99277342e-14,\n","        4.96631034e-16, 3.60431747e-15, 1.90768608e-14, 3.35160773e-14,\n","        4.97436944e-12, 1.04560111e-10, 2.42562553e-10, 9.80147123e-01,\n","        1.98528543e-02],\n","       [9.80435466e-09, 2.31594236e-12, 1.72773115e-17, 1.73621597e-08,\n","        1.00000000e+00, 4.36624292e-09, 2.19112627e-16, 8.11355161e-09,\n","        8.66502304e-14, 1.29421618e-09, 4.11026083e-15, 6.07867774e-14,\n","        1.02494283e-12],\n","       [2.25937086e-30, 1.61004709e-18, 2.79155588e-09, 8.39908871e-17,\n","        2.30154064e-25, 9.31352298e-24, 2.51881984e-14, 4.29588090e-23,\n","        1.55805993e-11, 1.70943305e-18, 1.00000000e+00, 7.11686543e-11,\n","        2.37096509e-10],\n","       [3.73333661e-13, 2.91085767e-11, 1.89301463e-08, 3.26683657e-04,\n","        4.57084097e-05, 9.60481472e-08, 2.53175112e-05, 9.99602020e-01,\n","        5.87808122e-13, 3.42569195e-10, 4.51552289e-08, 8.44251389e-08,\n","        1.13600263e-09],\n","       [6.44546293e-04, 3.58184704e-09, 1.40984696e-12, 5.70224614e-08,\n","        9.99348342e-01, 7.09180142e-07, 5.43956353e-16, 1.20908951e-11,\n","        1.08569174e-10, 1.18873352e-07, 1.29117881e-13, 4.44269954e-09,\n","        6.30352861e-06],\n","       [4.99175111e-11, 9.19468928e-12, 1.13966266e-07, 9.99992847e-01,\n","        4.40649774e-06, 5.59554681e-13, 8.25245870e-17, 5.06599712e-16,\n","        1.77448724e-19, 9.12240732e-19, 3.39397156e-11, 1.31441899e-10,\n","        2.62713525e-06],\n","       [2.09110895e-21, 6.93196094e-21, 7.40970989e-17, 1.00000000e+00,\n","        8.13423981e-12, 3.91495913e-27, 1.78333801e-31, 4.18667418e-32,\n","        0.00000000e+00, 0.00000000e+00, 3.91910397e-24, 2.90230939e-21,\n","        7.49382595e-16],\n","       [2.75382490e-08, 2.21005450e-10, 7.13256213e-07, 3.84422975e-07,\n","        1.11405916e-06, 1.10653889e-10, 3.55623968e-11, 3.90829313e-10,\n","        2.35059858e-07, 3.99916985e-07, 2.95807840e-05, 8.96136165e-01,\n","        1.03831299e-01],\n","       [2.68892716e-32, 4.33985969e-30, 1.82610369e-22, 1.00000000e+00,\n","        4.38063756e-14, 1.68583596e-32, 0.00000000e+00, 3.16581134e-36,\n","        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.70291077e-26,\n","        5.58536201e-24],\n","       [1.87562715e-10, 3.88955083e-11, 1.63752424e-14, 4.88771615e-19,\n","        1.00459421e-18, 1.00000000e+00, 3.94375130e-28, 2.04104133e-28,\n","        1.45980103e-29, 1.72820244e-21, 1.11575569e-29, 5.71875000e-25,\n","        1.02824150e-17],\n","       [1.00000000e+00, 2.66956266e-11, 9.64433147e-27, 2.01142760e-23,\n","        4.00702735e-12, 6.93090252e-10, 0.00000000e+00, 4.30901296e-37,\n","        4.16062833e-24, 3.29242699e-20, 4.12129407e-32, 7.68392868e-23,\n","        1.48635336e-12],\n","       [2.35567324e-23, 1.00000000e+00, 1.83177529e-30, 1.56672164e-24,\n","        1.78508259e-36, 2.00261777e-13, 3.23541590e-35, 0.00000000e+00,\n","        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00],\n","       [7.36621502e-08, 7.49206773e-12, 3.37415125e-16, 1.16219731e-07,\n","        9.99999762e-01, 3.17626758e-10, 5.41273078e-17, 1.34557587e-10,\n","        3.62779360e-13, 1.72806325e-10, 4.42582846e-14, 3.12926594e-11,\n","        6.15082318e-10],\n","       [9.60616254e-16, 7.24228524e-11, 4.24138701e-20, 2.61753564e-25,\n","        2.64995542e-26, 1.00000000e+00, 3.30675503e-25, 1.34152757e-28,\n","        5.96597821e-35, 1.64256001e-26, 9.28887776e-36, 1.71405098e-24,\n","        4.66455544e-24],\n","       [4.86473582e-22, 3.66940874e-21, 1.25169864e-17, 1.00000000e+00,\n","        1.70491624e-11, 3.60280672e-27, 1.04910637e-31, 1.69390123e-31,\n","        0.00000000e+00, 0.00000000e+00, 2.05598537e-25, 3.69432296e-22,\n","        2.54048938e-17],\n","       [2.32263282e-03, 1.61721749e-04, 2.09104340e-03, 6.37419929e-04,\n","        2.35818159e-02, 9.24727976e-01, 9.64411356e-06, 1.98654784e-03,\n","        6.11127348e-07, 9.28578724e-04, 1.66627137e-06, 2.72959983e-03,\n","        4.08207104e-02],\n","       [7.95744967e-14, 1.72626956e-16, 6.43218812e-11, 3.19436656e-14,\n","        6.05003489e-15, 6.41900405e-14, 6.53034349e-14, 1.73812001e-13,\n","        2.58782995e-10, 3.87430221e-09, 2.85503710e-09, 9.81530249e-01,\n","        1.84697323e-02],\n","       [5.67369797e-35, 1.32647208e-25, 1.00000000e+00, 5.29239041e-10,\n","        4.18368529e-26, 3.40984870e-14, 8.21193247e-20, 3.49343686e-28,\n","        1.45479829e-36, 8.69327337e-27, 4.58395371e-19, 1.84458265e-19,\n","        1.15647526e-10],\n","       [1.66450933e-35, 3.15880263e-21, 7.04944414e-09, 6.80991204e-18,\n","        3.46660589e-29, 2.91447281e-26, 6.28799398e-15, 4.58755835e-26,\n","        7.92515671e-14, 1.54530829e-21, 1.00000000e+00, 3.59066379e-12,\n","        2.13853796e-11],\n","       [3.80919119e-24, 1.00000000e+00, 2.43439308e-31, 3.80538390e-25,\n","        3.30575097e-37, 1.02471166e-13, 1.02570915e-35, 0.00000000e+00,\n","        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n","        0.00000000e+00],\n","       [2.86542098e-15, 5.47889290e-26, 1.28427453e-16, 2.53587597e-13,\n","        2.05678806e-15, 1.60731230e-23, 0.00000000e+00, 0.00000000e+00,\n","        3.08447014e-32, 1.91063470e-20, 3.70406995e-24, 4.66912949e-17,\n","        1.00000000e+00],\n","       [4.48201250e-14, 3.44970818e-12, 2.63350841e-10, 1.38336007e-04,\n","        5.01928953e-05, 5.32124611e-09, 2.97948418e-06, 9.99808490e-01,\n","        5.58822059e-14, 3.27339128e-11, 1.05695506e-08, 2.90134494e-09,\n","        1.56545801e-11],\n","       [8.52822695e-13, 7.68850053e-11, 1.26537403e-08, 4.76335554e-04,\n","        9.33176270e-05, 3.91373263e-08, 5.04372874e-05, 9.99379635e-01,\n","        2.11976964e-12, 3.36754430e-10, 1.44545339e-07, 9.80068791e-08,\n","        6.69823474e-10],\n","       [1.41588619e-09, 1.37013415e-10, 2.79714158e-07, 2.09825957e-09,\n","        6.56896537e-10, 4.45537918e-09, 2.17831531e-08, 2.34865407e-08,\n","        7.69865323e-07, 2.15744467e-06, 3.90890864e-06, 9.54322219e-01,\n","        4.56706062e-02],\n","       [1.81613115e-16, 5.31611176e-20, 3.38324160e-12, 1.07091625e-15,\n","        2.76482407e-17, 5.20265106e-16, 8.32358578e-16, 2.64874402e-15,\n","        1.76742328e-13, 1.47721783e-11, 8.05868480e-12, 9.83962178e-01,\n","        1.60377976e-02],\n","       [1.98105226e-07, 1.65703076e-10, 1.98887109e-12, 4.05787432e-06,\n","        9.99913096e-01, 1.70421652e-06, 9.03071942e-13, 8.03326184e-05,\n","        1.37623135e-10, 5.61219736e-07, 4.19768692e-10, 7.25967550e-11,\n","        7.59951035e-09]], dtype=float32)"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["model.predict(preprocess_data(X_val))"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["-----------------EVAUATION----------------\n","2/2 [==============================] - 0s 2ms/step - loss: 0.2591 - accuracy: 0.9365\n","LOSS:  0.2590975761413574\n","ACCURACY:  0.9365079402923584\n"]}],"source":["print('-----------------EVAUATION----------------')\n","loss, accuracy = model.evaluate(processed_X_val, y_val)\n","print('LOSS: ', loss)\n","print(\"ACCURACY: \", accuracy)"]}],"metadata":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"},"kernelspec":{"display_name":"Python 3.9.10 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.10"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
